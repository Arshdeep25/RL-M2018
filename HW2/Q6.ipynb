{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "stateValueMatrix - Represents the state value function for the 16 states (5X5) with i,j state stored in i*4+j index\n",
    "expectedRewardMatrix - Represents the expected reward given a state\n",
    "policyMatrix - Represents the probability of going from one state to another\n",
    "'''\n",
    "\n",
    "stateValueMatrix = np.zeros(16)\n",
    "expectedRewardMatrix = np.zeros(16)-1\n",
    "expectedRewardMatrix[0] = 0\n",
    "expectedRewardMatrix[15] = 0\n",
    "policyMatrix = np.zeros((16,16))\n",
    "theta = 1e-50\n",
    "gamma = 1\n",
    "\n",
    "\n",
    "'''\n",
    "This loop initialises the Policy Matrix, \n",
    "Example - \n",
    "If i==0 and j==0 or i==3 and j==3 i.e. the terminal state then it is only possible to go to the same state\n",
    "For corner positions it possible to stay in same state with 1/2 probability and go into other two states with 1/4 probability\n",
    "Similarly for others\n",
    "'''\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        index = i*4+j\n",
    "        if (i == 0 and j == 0) or (i==3 and j==3):\n",
    "            policyMatrix[index,index] = 1\n",
    "        elif i == 0 and j == 3:\n",
    "            policyMatrix[index,index] = 2/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "        elif i == 3 and j == 0:\n",
    "            policyMatrix[index,index] = 2/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif i == 0:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif j == 0:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif i == 3:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif j== 3:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "        else:\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Performing Policy Iteration to solve the Non Linear Equation \n",
    "\n",
    "The Policy Evalutation Step\n",
    "\n",
    "v(s) = Σ(a|s)Σp(s',r|s,a)[r+ gamma*v(s')] , for all s'. The outer summation is over a, the inner summation is over r and s'\n",
    "This Equation can be simplified to\n",
    "\n",
    "v(s) = Σrp(r|s) + gamma*(Σp(s'|s)v(s'))\n",
    "\n",
    "The Policy Improvement Step\n",
    "\n",
    "π'(s) = argmax (Σrp(r,a|s) + gamma*(Σp(s',a|s)v(s')))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#Loop for the whole policy iteration\n",
    "while True:\n",
    "    \n",
    "    #Printing Policy\n",
    "    print(policyMatrix)\n",
    "    \n",
    "    oldPolicyStateValue = np.copy(stateValueMatrix)\n",
    "    \n",
    "    #Loop for Policy Evaluation\n",
    "    while True:\n",
    "        maxDifference = 0\n",
    "        oldStateValueMatrix = np.copy(stateValueMatrix)\n",
    "        #Update Step\n",
    "        stateValueMatrix = expectedRewardMatrix + np.matmul(policyMatrix, stateValueMatrix)\n",
    "        stateValueMatrix[0] = 0\n",
    "        stateValueMatrix[15] = 0\n",
    "        stateValueMatrix = np.round(stateValueMatrix, decimals=1)\n",
    "        difference = abs(stateValueMatrix - oldStateValueMatrix)\n",
    "        if np.max(difference) < theta:\n",
    "            break\n",
    "    \n",
    "    #Printing Value Matrix\n",
    "    for row in range(4):\n",
    "        for col in range(4):\n",
    "            print(stateValueMatrix[row*4+col], end=\" \")\n",
    "        print()\n",
    "    \n",
    "    #Breaking Out of Policy Loop if Value Function using previous policy is same\n",
    "    if np.max(abs(oldPolicyStateValue - stateValueMatrix)) < theta:\n",
    "        break\n",
    "    \n",
    "    #Updating Policy\n",
    "    for i in range(16):\n",
    "        indices = []\n",
    "        value = []\n",
    "        for j in range(16):\n",
    "            if policyMatrix[i,j] > 0:\n",
    "                expectedReward = 0\n",
    "                if i != 0 and i != 15:\n",
    "                    expectedReward = -1\n",
    "                #Storing Value for Each action\n",
    "                value.append(policyMatrix[i,j]*expectedReward + policyMatrix[i,j] * stateValueMatrix[j])\n",
    "                indices.append(j)\n",
    "        #Taking the max of actions\n",
    "        value = np.round(value, decimals=1)\n",
    "        maxIndices = np.argwhere(value == np.max(value)).flatten()\n",
    "        numMaxIndices = len(maxIndices)\n",
    "        policyMatrix[i] = 0\n",
    "        #Updating with the max values\n",
    "        for j in range(len(maxIndices)):\n",
    "            policyMatrix[i, indices[maxIndices[j]]] = 1/numMaxIndices\n",
    "\n",
    "print(policyMatrix)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateValueMatrix = np.zeros(16)\n",
    "expectedRewardMatrix = np.zeros(16)-1\n",
    "expectedRewardMatrix[0] = 0\n",
    "expectedRewardMatrix[15] = 0\n",
    "policyMatrix = np.zeros((16,16))\n",
    "theta = 1e-50\n",
    "gamma = 0.9\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        index = i*4+j\n",
    "        if (i == 0 and j == 0) or (i==3 and j==3):\n",
    "            policyMatrix[index,index] = 1\n",
    "        elif i == 0 and j == 3:\n",
    "            policyMatrix[index,index] = 2/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "        elif i == 3 and j == 0:\n",
    "            policyMatrix[index,index] = 2/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif i == 0:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif j == 0:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif i == 3:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "        elif j== 3:\n",
    "            policyMatrix[index,index] = 1/4\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4\n",
    "        else:\n",
    "            policyMatrix[index, (i+1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i-1)*4+(j)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j+1)] = 1/4\n",
    "            policyMatrix[index, (i)*4+(j-1)] = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(policyMatrix)\n",
    "while True:\n",
    "    maxDifference = 0\n",
    "    oldStateValueMatrix = np.copy(stateValueMatrix)\n",
    "    \n",
    "    #Rather than updating the state value with the expected value over actions, taking the max over all actions\n",
    "    for i in range(1,15):\n",
    "        value = []\n",
    "        for j in range(16):\n",
    "            if policyMatrix[i,j] > 0:\n",
    "                value.append(policyMatrix[i,j]*expectedRewardMatrix[i] + policyMatrix[i,j]*stateValueMatrix[j])\n",
    "        #Updating with the max value\n",
    "        stateValueMatrix[i] = max(value)       \n",
    "    stateValueMatrix[0] = 0\n",
    "    stateValueMatrix[15] = 0\n",
    "    stateValueMatrix = np.round(stateValueMatrix, decimals=2)\n",
    "    \n",
    "    for row in range(4):\n",
    "        for col in range(4):\n",
    "            print(stateValueMatrix[row*4+col], end=\" \")\n",
    "        print()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    difference = abs(stateValueMatrix - oldStateValueMatrix)\n",
    "    if np.max(difference) < theta:\n",
    "        break\n",
    "\n",
    "#Updating Policy\n",
    "for i in range(16):\n",
    "    indices = []\n",
    "    value = []\n",
    "    for j in range(16):\n",
    "        if policyMatrix[i,j] > 0:\n",
    "            expectedReward = 0\n",
    "            if i != 0 and i != 15:\n",
    "                expectedReward = -1\n",
    "            #Storing Value for Each action\n",
    "            value.append(policyMatrix[i,j]*expectedReward + policyMatrix[i,j] * stateValueMatrix[j])\n",
    "            indices.append(j)\n",
    "    maxIndices = np.argwhere(value == np.max(value)).flatten()\n",
    "    numMaxIndices = len(maxIndices)\n",
    "    policyMatrix[i] = 0\n",
    "    for j in range(len(maxIndices)):\n",
    "        policyMatrix[i, indices[maxIndices[j]]] = 1/numMaxIndices\n",
    "\n",
    "print(policyMatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
